{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis\n",
    "   \n",
    "   <p>All requested statistics for the Boston Housing dataset are accurately calculated. Student correctly leverages NumPy functionality to obtain these results.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "\n",
    "print(\"Boston housing dataset has {} datapoints with {} variables each\".format(*data.shape))\n",
    "\n",
    "min_price = np.min(prices)\n",
    "print(\"Min:\"+\"\\n\"+str(min_price))\n",
    "\n",
    "max_price = np.max(prices)\n",
    "print(\"Max:\"+\"\\n\"+str(max_price))\n",
    "\n",
    "median_price = np.median(prices)\n",
    "print(\"Median:\"+\"\\n\"+str(median_price))\n",
    "\n",
    "std_price = np.std(prices)\n",
    "print(\"Standard Deviation:\"+\"\\n\"+str(std_price))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Feature Observation\n",
    "\n",
    "   \n",
    "   <p>\n",
    "    'RM' is the average number of rooms among homes in the neighborhood.\n",
    "    'LSTAT' is the percentage of homeowners in the neighborhood considered \"lower class\" (working poor). \n",
    "    'PTRATIO' is the ratio of students to teachers in primary and secondary schools in the neighborhood.\n",
    "    \n",
    "    Using your intuition, for each of the three features above, do you think that an increase in the value of that feature would lead to an increase in the value of 'MEDV' or a decrease in the value of 'MEDV'? Justify your answer for each.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:\n",
    "\n",
    "   <p>\n",
    "    <ul>\n",
    "    Independent variables:\n",
    "    <li>RM: Number of rooms in a house</li>\n",
    "    <li>LSTAT: Percentage of neighborhood population below poverty line.</li>\n",
    "    <li>PTR: Pupil-Teacher ratio</li>\n",
    "    </ul>\n",
    "    <ul>\n",
    "    Dependent variable:\n",
    "    <li>Price of the house</li>\n",
    "    </ul>\n",
    "    <ul>\n",
    "    Correlations:\n",
    "    <li>RM: Positively correlated to price. As RM goes up, price goes up, because people are simply willing to pay more money for a larger house with more rooms.</li>\n",
    "    <li>LSTAT: Negatively correlated to price. As LSTAT goes up, price goes down, because people are willing to pay more money to live in more affluent areas, which are likely to have more amenities, lower crime, etc.</li>\n",
    "    <li>PTR: Negatively correlated to price. As PTR goes up, price goes down, because people are willing to pay more for a house if their children will have access to a better school with more teachers.</li>\n",
    "    </ul>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Goodness of Fit\n",
    "   \n",
    "   <p>\n",
    "    Assume that a dataset contains five data points and a model made the following predictions for the target variable:\n",
    "    <br>\n",
    "    <table>\n",
    "        <tr><td>True Values</td><td>Predictions</td></tr>\n",
    "        <tr><td>3.0</td><td>2.5</td></tr>\n",
    "        <tr><td>-0.5</td><td>0.0</td></tr>\n",
    "        <tr><td>2.0</td><td>2.1</td></tr>\n",
    "        <tr><td> 7.0</td><td>7.8</td></tr>\n",
    "        <tr><td>4.2</td><td>5.3</td></tr>\n",
    "    </table>\n",
    "    <br>    \n",
    "    Run the code cell below to use the performance_metric function and calculate this model's coefficient of determination.\n",
    "  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the performance of this model\n",
    "score = performance_metric([3, -0.5, 2.7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\n",
    "print \"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "   <p>Would you consider this model to have successfully captured the variation of the target variable? Why or why not?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:\n",
    "\n",
    "   <p>The r2_score function was imported from sklearn.metrics and the arrays of true and predicted values were plugged in. The resulting value calculated was 0.923.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def performance_metric(y_true, y_predict):\n",
    "\tr2 = r2_score(y_true, y_predict)\n",
    "\treturn r2\n",
    "print(\"r2_score\"+\"\\n\"+str(performance_metric(y_train, y_train)))\n",
    "print(str(performance_metric([3, -0.5, 2.7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])))\n",
    ">>> 0.923"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   <p>I would say this metric is pretty successful in capturating the variation of the target variable for this data. The fairly high value of 0.923 indicates a fairly good correlation between the true and predicted values. While the predictions are off by about 0.1-1.0, the predictions are consistently higher for the higher values and lower for the lower values.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3:\n",
    "   \n",
    "   <p>What is the benefit to splitting a dataset into some ratio of training and testing subsets for a learning algorithm?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:\n",
    "   \n",
    "   <p>Saving a portion of the dataset for testing allows us to evaluate the strength of our model and determine if we are overfitting or underfitting. If the model works well for the training data but poorly for the testing data, then the model overfits. If the model works well on the testing data but poorly on the data as a whole, then the model underfits. \n",
    "    \n",
    "    Below, the code for splitting the dataset is shown: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "#Obtain the data\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices,\n",
    "\t\t\t\t\t\ttest_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4:\n",
    "   \n",
    "   <p>Choose one of the graphs above and state the maximum depth for the model.\n",
    "What happens to the score of the training curve as more training points are added? What about the testing curve?\n",
    "Would having more training points benefit the model?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "   \n",
    "   <p>Below, the learning curves prodcuded by the line 'vs.ModelLearning(features, prices)' in boston_housing.py are shown.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "   <p>Based on this these images, the best fit is the model with max_depth=3, because the score for the testing and training sets converge at a fairly high level. 150 data points is enough for the scores for the two sets to be nearly converged, and beyond 300 data points, the model does improve significantly. Initially before the curves coverge, as more data points are added, the score for the training set decreases and the score for the testing set increases.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "   \n",
    "   <p>When the model is trained with a maximum depth of 1, does the model suffer from high bias or from high variance?\n",
    "How about when the model is trained with a maximum depth of 10? What visual cues in the graph justify your conclusions?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "\n",
    "   <p>The model with max_depth 10 always has a high score for the training data, but never gets very good for the validation data no matter how many data points are provided. This is a model with high variance/overfitting.\n",
    "    \n",
    "    The model with a max_depth of 1 never has a very high score for either the training or validation sets, but the two score values converge fairly quickly. This is a model with high bias/underfitting.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "   \n",
    "   <p>Which maximum depth do you think results in a model that best generalizes to unseen data?\n",
    "What intuition lead you to this answer?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:\n",
    "   \n",
    "   <p>The best model appears to be the model with max_depth=3, because the scores for the training and testing sets seem to converge at a fairly high value, using a reasonable number of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "   \n",
    "   <p>What is the grid search technique? How it can be applied to optimize a learning algorithm?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "    \n",
    "   <p>The grid search technique tests a range of models against the data set, the models varying by two or more parameters, which can be imagined as axes on a grid or a number-line axis. Each point on the grid or axis represents a model. Each point is given a score, and the model at the best scoring point is the optimal model.\n",
    "   <br>\n",
    "   In this case, the parameter being optimized is the max depth of the decision tree used to fit the model to the data.\n",
    "   </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "   <p>What is the k-fold cross-validation training technique?\n",
    "What benefit does this technique provide for grid search when optimizing a model?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "   <p> With k-fold cross validation, we split the training data points into a number of (k) buckets. The model is trained k times, and each time a different one of the buckets is used for testing to obtain a score, while the remaining k-1 buckets areused for training. At the end, we average the scores for all the models. This allows us to more accurately evaluate the quality of each model in the grid search. \n",
    "   <br>\n",
    "   By testing on shuffled subsets of the data, we get an average score for each model and therefore end up with a model which is better representative of the data as a whole. If we train all the models in a grid search with the same training data and do not perform k-fold cross validation, then the model we end up identifying as \"best\" will likely be overfit to patterns in that training set which are not representative of the data as a whole. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "   <p>What maximum depth does the optimal model have? How does this result compare to your guess in Question 6?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "   <p>The code for my fit_model function is shown below: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def fit_model(X, y):\n",
    "        regressor = DecisionTreeRegressor()\n",
    "        parameters = {'max_depth':(1,2,3,4,5,6,7,8,9,10)}\n",
    "        scoring_function = make_scorer(performance_metric,\n",
    "         greater_is_better=True)\n",
    "        cv = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "        reg = GridSearchCV(regressor, parameters, scoring=scoring_function, cv=cv)\n",
    "        reg.fit(X,y)\n",
    "        print str(reg.best_estimator_)\n",
    "        return reg.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><p>The output of 'print str(reg.best_estimator_)' is shown below</p><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
    "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "           min_impurity_split=None, min_samples_leaf=1,\n",
    "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "           presort=False, random_state=None, splitter='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <p>The max_depth for this function is 4. This is close to my best guess of 3 from the learning curves.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10\n",
    "   <p> Imagine that you were a real estate agent in the Boston area looking to use this model to help price homes owned by your clients that they wish to sell. You have collected the following information from three of your clients:\n",
    "<table>    \n",
    "    <tr>\n",
    "        <td>Feature</td><td>Client 1</td><td>Client 2</td><td>Client 3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>total number of rooms in home</td><td>5</td><td>4</td><td>8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Neighborhood poverty (as %)</td>\n",
    "        <td>17%</td>\n",
    "        <td>32%</td>\n",
    "        <td>3%</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Student-teacher ratio</td>\n",
    "        <td>15-to-1</td>\n",
    "        <td>22-to-1</td>\n",
    "        <td>12-to-1</td>\n",
    "    </tr>\n",
    "\t\t    \t    \n",
    "</table>\n",
    "<br>\n",
    "What price would you recommend each client sell his/her home at?\n",
    "\n",
    "<br>\n",
    "Do these prices seem reasonable given the values for the respective features?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "   <p>The code for predicting the home values is shown below:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "client_data = [[5,17,15],[4,32,22],[8,3,12]]\n",
    "\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "        r2 = r2_score(y_true, y_predict)\n",
    "        return r2   \n",
    "print(\"r2 score\"+\"\\n\"+str(performance_metric(y_train, y_train)))\n",
    "\n",
    "def fit_model(X, y):\n",
    "        regressor = DecisionTreeRegressor()\n",
    "        parameters = {'max_depth':(1,2,3,4,5,6,7,8,9)}\n",
    "        scoring_function = make_scorer(performance_metric,\n",
    "         greater_is_better=True)\n",
    "        k_fold = KFold(n_splits=5)\n",
    "        reg = GridSearchCV(regressor, parameters, scoring=scoring_function, cv=k_fold)\n",
    "        reg.fit(X,y)\n",
    "        print str(reg.best_estimator_)\n",
    "        return reg.best_estimator_\n",
    "\n",
    "print(\"Predicted sales prices for client input data:\"+\"\\n\"+str(fit_model(features, prices).predict(client_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicted sales prices for client input data:\n",
    ">>[ 408800, 231253.44827586, 938053.84615385]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <p>Below, the partial output of features.describe() is shown, alognside the pricing stats obtained in the statistical analysis section above</p>\n",
    "   <table>\n",
    "       <tr><td>Prices:</td><td></td></tr>\n",
    "       <tr><td>Min:</td><td>105000</td></tr>\n",
    "       <tr><td>Median:</td><td>438900</td></tr>\n",
    "       <tr><td>Max:</td><td>1024800</td></tr>\n",
    "       <tr><td>std</td><td>165171</td></tr>\n",
    "   </table>\n",
    "   \n",
    "   <table>\n",
    "    <tr><td>Features:</td><td>RM</td><td>LSTAT</td><td>PTRATIO</td></tr>\n",
    "    <tr><td>std</td><td>0.643650</td><td>7.081990</td><td>2.111268</td></tr>\n",
    "    <tr><td>min</td><td>3.561000</td><td>1.980000</td><td>12.600000</td></tr>\n",
    "    <tr><td>mean</td><td>6.240288</td><td>12.939632</td><td>18.516564</td></tr>\n",
    "    <tr><td>max</td><td>8.398000</td><td>37.970000</td><td>22.000000</td></tr>\n",
    "   </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Based on the above, client 1 is more that 1 standard-deviation below average number of rooms, less than 1 standard-deviation above average poverty in the area, and more than one standard deviation below (better than) average PTR. In other the words, the house is a little on the small side, in a somewhat low-income neighborhood, but near a pretty good school. One might say these features describe a house which is overall \"average\".<br>The predicted price is within one standard deviation of the median price, which is about what we'd expect.</li>\n",
    "<li>Client 2 is several standard deviations below the average number of rooms. The LSTAT is within one standard deviation of the average (on the high side). The PTR is the highest (worst) in the city. These features describe a house which is below average by all of our metrics. It is small, in a low-income neighborhood, and the schools have very large class sizes.<br>The predicted price is appropriately over 1 standard deviation below average. Again, this is about what we'd expect.</li>\n",
    "<li>Client 3 is over 1 standard deviation over the average number of rooms. LSTAT is well over 1 standard deviation below average. The PTR is actually below (better than) the minimum in the dataset. All of these features describe a house which is above average. It is big, in a high-income neighborhood, and near great schools. The predicted price is appropriately several standard deviations above the average. Again, this is what we'd expect.</li>\n",
    "</ul>\n",
    "<p>Overall, these numbers seem reasonable for the houses.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 11\n",
    "   <br><p>In a few sentences, discuss whether the constructed model should or should not be used in a real-world setting.</p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer\n",
    "   <br><p>While this model could be useful for making very loose calculations, it is not suitable for real-world use, e.g. at a real estate company, for a number of reasons.</p><br>\n",
    "   <ul>\n",
    "    <li>The data is outdated. Shifts in the housing market and inflation have certainly impacted prices.</li>\n",
    "    <li>There are many other factors that need to be considered in appraising a house, such as a garage, a lawn, a living room, central air, etc.</li>\n",
    "    <li>The model likely puts too much emphasis on variables pertaining to the neighborhood the house is in, and not enough emphasis on variables pertaining to the house itself. The geographical boundaries by which these neighborhoods are divided may not be optimial or accurately reflect the quality of life at a certain address.</li>\n",
    "    <li>For instance, consider that a home near below average schools and only 1 bedroom may be worth more if it is near local nighlife, as more non-family buyers might be interested.</li>\n",
    "   </ul>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
